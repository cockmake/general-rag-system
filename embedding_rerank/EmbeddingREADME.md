# Embedding Service - å®Œæ•´æ–‡æ¡£

åŸºäºvLLMå’ŒQwen3-Embedding-0.6Bçš„é«˜æ€§èƒ½å‘é‡åŒ–æœåŠ¡

## ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [APIæ¥å£](#apiæ¥å£)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)

## æ¦‚è¿°

Embedding Serviceæ˜¯ä¸€ä¸ªç”Ÿäº§çº§çš„æ–‡æœ¬å‘é‡åŒ–æœåŠ¡ï¼Œæä¾›ï¼š

### æ ¸å¿ƒç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½æ¨ç†**: åŸºäºvLLMå¼•æ“ï¼Œæ”¯æŒGPUåŠ é€Ÿ
- ğŸ“¦ **æ‰¹é‡å¤„ç†**: é«˜æ•ˆçš„æ‰¹é‡å‘é‡åŒ–
- ğŸ”§ **çµæ´»é…ç½®**: æ”¯æŒç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶
- ğŸŒ **æ ‡å‡†API**: å…¼å®¹OpenAI Embeddings APIæ ¼å¼
- ğŸ“Š **å®Œæ•´ç›‘æ§**: è¯¦ç»†çš„æ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡
- ğŸ”„ **ç”Ÿäº§å°±ç»ª**: å¥åº·æ£€æŸ¥ã€ä¼˜é›…å…³é—­ç­‰

### æŠ€æœ¯æ ˆ

- **æ¨ç†å¼•æ“**: vLLM 0.8.5+
- **æ¨¡å‹**: Qwen3-Embedding-0.6B
- **æ¡†æ¶**: FastAPI + Uvicorn
- **é…ç½®**: Pydantic
- **è¯­è¨€**: Python 3.8+

## ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|---------|---------|
| CPU | 4æ ¸ | 8æ ¸+ |
| å†…å­˜ | 8GB | 16GB+ |
| GPU | - | NVIDIA GPU (4GB+ æ˜¾å­˜) |
| ç£ç›˜ | 10GB | 20GB+ SSD |

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è), macOS, Windows
- **Python**: 3.8, 3.9, 3.10, 3.11
- **CUDA**: 11.8+ (ä½¿ç”¨GPUæ—¶)
- **é©±åŠ¨**: NVIDIA Driver 450.80.02+

### ä¾èµ–åŒ…

```txt
vllm>=0.8.5
fastapi>=0.100.0
uvicorn>=0.23.0
transformers>=4.30.0
torch>=2.0.0
pydantic>=2.0.0
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install vllm>=0.8.5 fastapi uvicorn transformers torch pydantic

# å…‹éš†ä»£ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
git clone <repository-url>
cd embedding_rerank
```

### 2. é…ç½®

ç›´æ¥ç¼–è¾‘é…ç½®æ–‡ä»¶ `config/embedding_config.py` è¿›è¡Œé…ç½®ï¼š

```bash
nano config/embedding_config.py
```

### 3. å¯åŠ¨

```bash
python embedding_start.py
```

å¯åŠ¨æˆåŠŸåï¼ŒæœåŠ¡å°†åœ¨ `http://0.0.0.0:8890` è¿è¡Œã€‚

### 4. éªŒè¯

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8890/health

# ç”Ÿæˆå‘é‡
curl -X POST http://localhost:8890/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"input": ["Hello, world!"]}'
```

## é…ç½®è¯´æ˜

### é…ç½®æ–¹å¼

è¯·ç›´æ¥ä¿®æ”¹ `config/embedding_config.py` æ–‡ä»¶ä¸­çš„ `EmbeddingConfig` ç±»å±æ€§ã€‚

### å®Œæ•´é…ç½®é€‰é¡¹

#### æ¨¡å‹é…ç½®

```python
# æ¨¡å‹åç§°ï¼ˆHuggingFaceæ¨¡å‹IDï¼‰
model_name: str = "Qwen/Qwen3-Embedding-0.6B"

# æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆäºmodel_nameï¼‰
model_path: Optional[str] = None
```

#### GPUé…ç½®

```python
# GPUå†…å­˜ä½¿ç”¨ç‡ (0.0-1.0)
gpu_memory_utilization: float = 0.4

# æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆtokensï¼‰
max_model_len: int = 3072

# å¼ é‡å¹¶è¡Œå¤§å°ï¼ˆGPUæ•°é‡ï¼‰
tensor_parallel_size: int = 1

# æ•°æ®ç±»å‹
dtype: str = "float16"  # å¯é€‰: float16, bfloat16, float32
```

#### æœåŠ¡é…ç½®

```python
# ç›‘å¬åœ°å€
host: str = "0.0.0.0"

# æœåŠ¡ç«¯å£
port: int = 8890

# å·¥ä½œè¿›ç¨‹æ•°ï¼ˆæ¨èè®¾ä¸º1ï¼‰
workers: int = 1
```

#### æ‰¹å¤„ç†é…ç½®

```python
# æœ€å¤§æ‰¹å¤„ç†å¤§å°
max_batch_size: int = 32

# æ‰¹å¤„ç†è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
batch_timeout_ms: int = 10
```

#### æ—¥å¿—é…ç½®

```python
# æ—¥å¿—çº§åˆ«: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_level: str = "INFO"
```

### é…ç½®ç¤ºä¾‹

**ç”Ÿäº§ç¯å¢ƒ**
ä¿®æ”¹ `config/embedding_config.py`:
```python
gpu_memory_utilization: float = 0.8
max_model_len: int = 3072
tensor_parallel_size: int = 1
log_level: str = "WARNING"
```

**å¼€å‘ç¯å¢ƒ**
ä¿®æ”¹ `config/embedding_config.py`:
```python
gpu_memory_utilization: float = 0.3
max_model_len: int = 2048
port: int = 8890
log_level: str = "DEBUG"
```

**å¤šGPUç¯å¢ƒ**
ä¿®æ”¹ `config/embedding_config.py`:
```python
tensor_parallel_size: int = 4
gpu_memory_utilization: float = 0.9
max_model_len: int = 3072
```

## APIæ¥å£

### ç«¯ç‚¹åˆ—è¡¨

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/` | GET | æœåŠ¡ä¿¡æ¯ |
| `/health` | GET | å¥åº·æ£€æŸ¥ |
| `/v1/embeddings` | POST | ç”Ÿæˆå‘é‡ï¼ˆæ ‡å‡†ï¼‰ |
| `/embeddings` | POST | ç”Ÿæˆå‘é‡ï¼ˆç®€åŒ–ï¼‰ |

### è¯¦ç»†è¯´æ˜

#### 1. GET `/health`

å¥åº·æ£€æŸ¥ç«¯ç‚¹

**å“åº”ç¤ºä¾‹**
```json
{
  "status": "healthy",
  "model": "Qwen/Qwen3-Embedding-0.6B",
  "gpu_memory_utilization": 0.4,
  "max_model_len": 3072,
  "device": "cuda"
}
```

#### 2. POST `/v1/embeddings`

ç”Ÿæˆæ–‡æœ¬å‘é‡

**è¯·æ±‚å‚æ•°**

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| input | string/array | âœ“ | è¾“å…¥æ–‡æœ¬ |
| instruction | string | âœ— | ä»»åŠ¡æŒ‡ä»¤ |
| model | string | âœ— | æ¨¡å‹åç§°ï¼ˆå¿½ç•¥ï¼‰ |

**è¯·æ±‚ç¤ºä¾‹**

å•ä¸ªæ–‡æœ¬ï¼š
```json
{
  "input": "What is the capital of China?"
}
```

æ‰¹é‡æ–‡æœ¬ï¼š
```json
{
  "input": [
    "What is the capital of China?",
    "Explain gravity"
  ]
}
```

å¸¦æŒ‡ä»¤ï¼š
```json
{
  "input": ["Query text"],
  "instruction": "Given a web search query, retrieve relevant passages"
}
```

**å“åº”æ ¼å¼**

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "index": 0,
      "embedding": [0.123, -0.456, ...]
    }
  ],
  "model": "Qwen/Qwen3-Embedding-0.6B",
  "usage": {
    "prompt_tokens": 10,
    "total_tokens": 10
  }
}
```

**çŠ¶æ€ç **

- `200`: æˆåŠŸ
- `400`: è¯·æ±‚å‚æ•°é”™è¯¯
- `500`: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
- `503`: æ¨¡å‹æœªåŠ è½½

### ä½¿ç”¨ç¤ºä¾‹

#### Python

```python
import requests

# åŸºç¡€ç”¨æ³•
response = requests.post(
    "http://localhost:8890/v1/embeddings",
    json={"input": "Hello, world!"}
)
data = response.json()
embedding = data["data"][0]["embedding"]

# æ‰¹é‡å¤„ç†
texts = ["Text 1", "Text 2", "Text 3"]
response = requests.post(
    "http://localhost:8890/v1/embeddings",
    json={"input": texts}
)
embeddings = [d["embedding"] for d in response.json()["data"]]

# å¸¦æŒ‡ä»¤
response = requests.post(
    "http://localhost:8890/v1/embeddings",
    json={
        "input": ["Query: Machine learning"],
        "instruction": "Represent this sentence for searching relevant passages"
    }
)

# é”™è¯¯å¤„ç†
try:
    response = requests.post(url, json=payload, timeout=30)
    response.raise_for_status()
    data = response.json()
except requests.exceptions.Timeout:
    print("è¯·æ±‚è¶…æ—¶")
except requests.exceptions.HTTPError as e:
    print(f"HTTPé”™è¯¯: {e.response.status_code}")
except Exception as e:
    print(f"é”™è¯¯: {e}")
```

#### JavaScript/Node.js

```javascript
const axios = require('axios');

// åŸºç¡€ç”¨æ³•
async function getEmbedding(text) {
  const response = await axios.post('http://localhost:8890/v1/embeddings', {
    input: text
  });
  return response.data.data[0].embedding;
}

// æ‰¹é‡å¤„ç†
async function getBatchEmbeddings(texts) {
  const response = await axios.post('http://localhost:8890/v1/embeddings', {
    input: texts
  });
  return response.data.data.map(d => d.embedding);
}

// ä½¿ç”¨
const embedding = await getEmbedding("Hello, world!");
const embeddings = await getBatchEmbeddings(["Text 1", "Text 2"]);
```

#### cURL

```bash
# å•ä¸ªæ–‡æœ¬
curl -X POST http://localhost:8890/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"input": "Hello, world!"}'

# æ‰¹é‡æ–‡æœ¬
curl -X POST http://localhost:8890/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"input": ["Text 1", "Text 2", "Text 3"]}'

# å¸¦æŒ‡ä»¤
curl -X POST http://localhost:8890/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "input": ["Query text"],
    "instruction": "Represent for retrieval"
  }'
```

## æ€§èƒ½ä¼˜åŒ–

### æ€§èƒ½æŒ‡æ ‡

| åœºæ™¯ | æ‰¹é‡å¤§å° | å»¶è¿Ÿ | ååé‡ |
|------|---------|------|--------|
| å•ä¸ªæ–‡æœ¬ | 1 | 50-100ms | 10-20 texts/s |
| å°æ‰¹é‡ | 10 | 150-250ms | 40-60 texts/s |
| å¤§æ‰¹é‡ | 32 | 400-600ms | 50-80 texts/s |

*åŸºäºNVIDIA A100 GPUæµ‹è¯•*

### ä¼˜åŒ–ç­–ç•¥

#### 1. æ‰¹é‡å¤„ç†

âŒ **ä¸æ¨è**
```python
for text in texts:
    response = requests.post(url, json={"input": text})
```

âœ… **æ¨è**
```python
response = requests.post(url, json={"input": texts})
```

æ‰¹é‡å¤„ç†å¯ä»¥æé«˜ååé‡5-10å€ã€‚

#### 2. è¿æ¥å¤ç”¨

```python
import requests

session = requests.Session()
session.headers.update({"Content-Type": "application/json"})

for batch in batches:
    response = session.post(url, json={"input": batch})
```

#### 3. GPUé…ç½®ä¼˜åŒ–

ä¿®æ”¹ `config/embedding_config.py`:
```python
# å¦‚æœæœ‰è¶³å¤Ÿæ˜¾å­˜ï¼Œæé«˜åˆ©ç”¨ç‡
gpu_memory_utilization: float = 0.8

# å¢åŠ æ‰¹å¤„ç†å¤§å°
max_batch_size: int = 64
```

#### 4. å¤šGPUéƒ¨ç½²

ä¿®æ”¹ `config/embedding_config.py`:
```python
# ä½¿ç”¨4ä¸ªGPU
tensor_parallel_size: int = 4
```

#### 5. å¤šå®ä¾‹è´Ÿè½½å‡è¡¡

å¯ä»¥å¯åŠ¨å¤šä¸ªå®ä¾‹ç›‘å¬ä¸åŒç«¯å£ï¼Œéœ€è¦åˆ›å»ºå¤šä¸ªé…ç½®æ–‡ä»¶æˆ–ä»£ç ä¸­åŠ¨æ€ä¿®æ”¹ã€‚


### æ€§èƒ½ç›‘æ§

æœåŠ¡æä¾›è¯¦ç»†çš„æ€§èƒ½æ—¥å¿—ï¼š

```
INFO: Processing 32 texts for embedding
INFO: Generated 32 embeddings in 0.523s (61.2 texts/s)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. CUDA out of memory

**ç—‡çŠ¶**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ³•**:
ä¿®æ”¹ `config/embedding_config.py`:
```python
# é™ä½æ˜¾å­˜ä½¿ç”¨ç‡
gpu_memory_utilization: float = 0.3

# å‡å°æœ€å¤§é•¿åº¦
max_model_len: int = 2048

# å‡å°æ‰¹å¤„ç†å¤§å°
max_batch_size: int = 16
```

#### 2. æ¨¡å‹ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**: `OSError: Can't load tokenizer`

**è§£å†³æ–¹æ³•**:
```bash
# ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```
æˆ–ä¿®æ”¹ `config/embedding_config.py` ä½¿ç”¨æœ¬åœ°è·¯å¾„:
```python
model_path: str = "/path/to/model"
```

#### 3. ç«¯å£è¢«å ç”¨

**ç—‡çŠ¶**: `Address already in use`

**è§£å†³æ–¹æ³•**:
ä¿®æ”¹ `config/embedding_config.py`:
```python
# æ›´æ”¹ç«¯å£
port: int = 9000
```

æˆ–é‡Šæ”¾ç«¯å£:
```bash
lsof -ti:8890 | xargs kill -9
```

#### 4. æ²¡æœ‰GPU

æœåŠ¡ä¼šè‡ªåŠ¨é™çº§åˆ°CPUæ¨¡å¼ï¼Œä½†æ€§èƒ½è¾ƒä½ã€‚

å»ºè®®ä½¿ç”¨GPUæˆ–è€ƒè™‘ä½¿ç”¨æ›´è½»é‡çš„æ¨¡å‹ã€‚

#### 5. å‘é‡ç»´åº¦ä¸åŒ¹é…

Qwen3-Embedding-0.6Bè¾“å‡ºç»´åº¦ä¸º**1024**ï¼Œç¡®ä¿ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨ç›¸åŒç»´åº¦ã€‚

### æ—¥å¿—åˆ†æ

ä¿®æ”¹é…ç½®æ–‡ä»¶å¯ç”¨DEBUGæ—¥å¿—æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼š

```python
# config/embedding_config.py
log_level: str = "DEBUG"
```

```bash
python embedding_start.py
```

## æœ€ä½³å®è·µ

### ç”Ÿäº§éƒ¨ç½²

#### 1. ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨

**SystemdæœåŠ¡**

```ini
[Unit]
Description=Embedding Service
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/opt/embedding_rerank
Environment="EMBEDDING_GPU_MEMORY_UTILIZATION=0.7"
ExecStart=/usr/bin/python3 embedding_start.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

#### 2. åå‘ä»£ç†

**Nginxé…ç½®**

```nginx
upstream embedding_backend {
    server 127.0.0.1:8890;
    # å¦‚æœ‰å¤šå®ä¾‹
    # server 127.0.0.1:8891;
}

server {
    listen 80;
    server_name embedding.example.com;

    location / {
        proxy_pass http://embedding_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_read_timeout 300s;
    }
}
```

#### 3. å®¹å™¨åŒ–éƒ¨ç½²

**Dockerfile**

```dockerfile
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

RUN apt-get update && apt-get install -y python3 python3-pip
RUN pip3 install vllm fastapi uvicorn transformers torch

COPY . /app
WORKDIR /app

EXPOSE 8890

CMD ["python3", "embedding_start.py"]
```

### å®‰å…¨å»ºè®®

1. **APIè®¤è¯**: æ·»åŠ APIå¯†é’¥éªŒè¯
2. **é€Ÿç‡é™åˆ¶**: é˜²æ­¢æ»¥ç”¨
3. **è¾“å…¥éªŒè¯**: é™åˆ¶è¾“å…¥é•¿åº¦
4. **HTTPS**: ä½¿ç”¨SSL/TLSåŠ å¯†
5. **é˜²ç«å¢™**: é™åˆ¶è®¿é—®IP

### ç›‘æ§å»ºè®®

1. **å¥åº·æ£€æŸ¥**: å®šæœŸè°ƒç”¨`/health`ç«¯ç‚¹
2. **æ€§èƒ½ç›‘æ§**: è®°å½•å»¶è¿Ÿã€ååé‡
3. **èµ„æºç›‘æ§**: GPU/CPU/å†…å­˜ä½¿ç”¨ç‡
4. **æ—¥å¿—æ”¶é›†**: é›†ä¸­åŒ–æ—¥å¿—ç®¡ç†
5. **å‘Šè­¦**: å¼‚å¸¸æƒ…å†µåŠæ—¶é€šçŸ¥

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2026-02-03)

- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒQwen3-Embedding-0.6Bæ¨¡å‹
- âœ… å…¼å®¹OpenAI Embeddings API
- âœ… æ‰¹é‡å¤„ç†æ”¯æŒ
- âœ… å¥åº·æ£€æŸ¥ç«¯ç‚¹
- âœ… å®Œæ•´çš„é…ç½®ç³»ç»Ÿ
- âœ… ç”Ÿäº§çº§é”™è¯¯å¤„ç†

## ç›¸å…³æ–‡æ¡£

- **å¿«é€Ÿå¼€å§‹**: [EmbeddingQUICKSTART.md](EmbeddingQUICKSTART.md)
- **APIå‚è€ƒ**: [EmbeddingAPI.md](EmbeddingAPI.md)

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªQwenæ¨¡å‹çš„è®¸å¯è¯æ¡æ¬¾ã€‚

## æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥é˜…ï¼š
1. æœ¬æ–‡æ¡£çš„[æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)éƒ¨åˆ†
2. [APIæ–‡æ¡£](EmbeddingAPI.md)
3. [å¿«é€Ÿå¼€å§‹æŒ‡å—](EmbeddingQUICKSTART.md)
